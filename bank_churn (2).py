# -*- coding: utf-8 -*-
"""bank_churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GLQ4PYXH8MrwgJwS1BVZLYZAA5tsJj2J

**Customer Churn prediction:-**

 Customer Churn prediction means knowing which customers are likely to leave or unsubscribe from your service. For many companies, this is an important prediction. This is because acquiring new customers often costs more than retaining existing ones. Once youâ€™ve identified customers at risk of churn, you need to know exactly what marketing efforts you should make with each customer to maximize their likelihood of staying.




Customers have different behaviors and preferences, and reasons for cancelling their subscriptions. Therefore, it is important to actively communicate with each of them to keep them on your customer list. You need to know which marketing activities are most effective for individual customers and when they are most effective.
"""

# importing the require libarary

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from google.colab import drive
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, classification_report, ConfusionMatrixDisplay



#importing the drive from the google
from google.colab import drive
drive.mount('/content/drive')

#load the data sheet from the drive
churn= pd.read_csv("/content/drive/MyDrive/ZummitAfrica(AI ML Learning Path)/1_project customer churn prediction /Churn_Modelling.csv")

# Display information about the dataset, including data types and missing values
churn.info()

# Display information about the dataset, including data types and missing values
churn.info()

# Display summary statistics of the dataset
churn.describe()

"""#Auto EDA process"""

'''!pip install matplotlib
!pip install pandas-profiling
!pip install --upgrade pandas
!pip install --upgrade numpy
!pip install --upgrade matplotlib
!pip install --upgrade seaborn
!pip install --upgrade scikit-learn
!pip install sweetviz'''

"""Restart the kernal once again"""

'''import matplotlib.pyplot as plt
import sweetviz as sv'''

'''# Analyze the dataset
report = sv.analyze(churn)

# Display the report
report.show_html("churn_eda_report.html")'''

"""#EDA  (Exploratory Data Analysis)"""

# Get the dimensions of the dataset (rows, columns)
churn.shape

# Get the total number of elements in the dataset
churn.size

# Get the names of the columns in the dataset
churn.columns

# Count missing values in each column
churn.isnull().sum()

# Identify and display duplicate rows based on the 'customer_id' column
duplicates = churn[churn.duplicated(subset=['CustomerId'], keep=False)]
print(duplicates)

"""# Data Visualization"""

# Set the figure size for the following visualization
plt.figure(figsize=(15, 5))

# Create a count plot to visualize the distribution of the 'exited' variable in the original dataset
sns.countplot(data=churn, x='Exited')

!pip install plotly

# Display the count of each class in the 'exited' variable
churn['Exited'].value_counts().to_frame()

# Class Imbalance Resampling
# Select the majority and minority classes
churn_majority = churn[churn['Exited'] == 0]
churn_minority = churn[churn['Exited'] == 1]

from sklearn.utils import resample

# Downsample the majority class to match the size of the minority class
churn_minority_upsampled = resample(churn_minority, n_samples=len(churn_majority), replace=True, random_state=42)

# Combine the resampled majority class with the minority class
churn_df = pd.concat([churn_majority, churn_minority_upsampled])

# Set the figure size for the following visualization
plt.figure(figsize=(15, 5))

# Create a count plot to visualize the distribution of the 'exited' variable in the resampled dataset
sns.countplot(data=churn_df, x='Exited')

# Display the column names in the 'churn_df' DataFrame
churn_df.columns

sns.countplot(x='Gender', data=churn_df,hue='Exited')

sns.countplot(x='Geography', data=churn_df,hue='Exited')



# Remove specific columns from the 'churn_df' DataFrame
# These columns include 'rownumber,' 'customerid,' 'surname,' 'geography,' and 'gender.'
churn_df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)

# Define the mapping of values
mapping = {"Spain": 1, "France": 2, "Germany": 3}

# Use the replace function to map the values in the "Geography" column
churn_df["Geography"] = churn_df["Geography"].replace(mapping)

churn_df['Gender'] = churn_df['Gender'].replace({'Male': 1, 'Female': 0})

# Compute the correlation matrix for the remaining columns in the 'churn_df' DataFrame
churn_df.corr()

# Create a heatmap to visualize the correlation between different features
# The 'annot=True' parameter adds values to the heatmap
plt.figure(figsize=(15, 5))
sns.heatmap(churn_df.corr(), annot=True)

# Calculate the correlation of each feature with the 'exited' variable and store it in 'df_corr_exit'
df_corr_exit = churn_df.corr()['Exited'].to_frame()

# Create a bar plot to visualize the correlation of each feature with the 'exited' variable
plt.figure(figsize=(15, 5))
sns.barplot(data=df_corr_exit, x=df_corr_exit.index, y='Exited')

# Separate the feature columns (independent variables) into 'x'
x = churn_df.drop(['Exited'], axis=1)
# Separate the target variable ('exited') into 'y'
y = churn_df['Exited']

"""#Spliting the Data Set"""

# Import the necessary function from scikit-learn
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
# x: Features (independent variables)
# y: Target variable (dependent variable)
# test_size: The proportion of the data to include in the test split (in this case, 30% for testing)
# random_state: A random seed for reproducibility
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

# Print the dimensions of the resulting datasets
x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""#Modeling and Evaluation"""

from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler on the training data and transform it
x_train_scaled = scaler.fit_transform(x_train)
#y_train_scaled = scaler.fit_transform(y_train)

# Transform the test data using the same scaler
x_test_scaled = scaler.transform(x_test)
#y_test_scaled = scaler.transform(y_test)

# Import the logistic regression model from scikit-learn
from sklearn.linear_model import LogisticRegression

# Create a logistic regression model with a specified maximum number of iterations
lr = LogisticRegression(max_iter=500)

# Train the logistic regression model on the training data
lr.fit(x_train_scaled, y_train)
#lr.fit(x_train_scaled, y_train_scaled)

# Calculate the accuracy score on the training set
train_accuracy = lr.score(x_train_scaled, y_train)
print("Training Accuracy:", train_accuracy)

# Predict outcomes on the test set
y_pred = lr.predict(x_test_scaled)

# Predict outcomes on the test set
y_pred = lr.predict(x_test_scaled)

# Import necessary functions for performance evaluation
from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score, ConfusionMatrixDisplay

# Calculate the precision score on the test set
test_precision = precision_score(y_test, y_pred)
print("Test Precision Score:", test_precision)

# Calculate the recall score on the test set
test_recall = recall_score(y_test, y_pred)
print("Test Recall Score:", test_recall)

# Calculate the accuracy score on the test set
test_accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy Score:", test_accuracy)

from sklearn.metrics import classification_report

# Calculate the F1 score on the test set
#test_f1 = f1_score(y_test, y_pred)
print(classification_report(y_pred,y_test))
#print("Test F1 Score:", test_f1)

# Create a ConfusionMatrixDisplay object for visualization
cmd = ConfusionMatrixDisplay(
    confusion_matrix=confusion_matrix(y_test, y_pred, labels=lr.classes_),
    display_labels=lr.classes_
)
# Plot the confusion matrix
cmd.plot()

"""#k-Nearest Neighbors (KNN)"""

# Import and create a KNN classifier with k=3
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)

# Train the KNN model on the training data
knn.fit(x_train_scaled, y_train)

# Calculate the accuracy score on the training set for KNN
knn_train_accuracy = knn.score(x_train_scaled, y_train)
print("KNN Training Accuracy:", knn_train_accuracy)

# Calculate the accuracy score on the test set for KNN
y_pred = knn.predict(x_test_scaled)
print(classification_report(y_pred,y_test))

"""#Support Vector Classifier (SVC):"""

# Import and create an SVC classifier
from sklearn.svm import SVC
svc = SVC()

# Train the SVC model on the training data
svc.fit(x_train_scaled, y_train)

# Calculate the accuracy score on the training set for SVC
svc_train_accuracy = svc.score(x_train_scaled, y_train)
print("SVC Training Accuracy:", svc_train_accuracy)

# Calculate the accuracy score on the test set for SVC


y_pred = svc.predict(x_test_scaled)
print(classification_report(y_pred,y_test))

"""#Random Forest"""

from sklearn.model_selection import GridSearchCV

from sklearn.ensemble import RandomForestClassifier

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
}

grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                           param_grid=param_grid,
                           scoring='accuracy',
                           cv=5,  # Cross-validation folds
                           verbose=2,  # Higher values give more information
                           n_jobs=-1)  # Use all available CPU cores for parallelization

# Create a Random Forest classifier
rf = RandomForestClassifier(random_state=42)

# Fit the GridSearchCV object
grid_search.fit(x_train_scaled, y_train)

# Get the best model
best_rf = grid_search.best_estimator_

# Predictions using the best model
y_pred_rf = best_rf.predict(x_test_scaled)

print(classification_report(y_pred_rf,y_test))

# Print the best hyperparameters
print("Best hyperparameters:", grid_search.best_params_)

# Print the best cross-validation score
print("Best cross-validation score:", grid_search.best_score_)

grid_search.score(x_train_scaled, y_train)

import pickle

# Save the SVC model to a pickle file
with open('rfc_model.pkl', 'wb') as model_file:
    pickle.dump(best_rf, model_file)

print("best_rf model saved as 'rfc_model.pkl'")

pip freeze

import pickle

# Save the SVC model to a pickle file
with open('svc_model.pkl', 'wb') as model_file:
    pickle.dump(svc, model_file)

print("svc model saved as 'svm_model.pkl'")

"""conclution :-
the best model for the data sheet is knn with test accuracy of 83.16% and train accuracy of 89.52%
"""